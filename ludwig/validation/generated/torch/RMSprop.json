{
    "docstring": "Implements RMSprop algorithm.\n\n.. math::\n   \\begin{aligned}\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{input}      : \\alpha \\text{ (alpha)},\\: \\gamma \\text{ (lr)},\n            \\: \\theta_0 \\text{ (params)}, \\: f(\\theta) \\text{ (objective)}                   \\\\\n        &\\hspace{13mm}   \\lambda \\text{ (weight decay)},\\: \\mu \\text{ (momentum)},\\: centered\\\\\n        &\\textbf{initialize} : v_0 \\leftarrow 0 \\text{ (square average)}, \\:\n            \\textbf{b}_0 \\leftarrow 0 \\text{ (buffer)}, \\: g^{ave}_0 \\leftarrow 0     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                                 \\\\\n        &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n        &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n        &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n        &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n        &\\hspace{5mm}v_t           \\leftarrow   \\alpha v_{t-1} + (1 - \\alpha) g^2_t\n            \\hspace{8mm}                                                                     \\\\\n        &\\hspace{5mm} \\tilde{v_t} \\leftarrow v_t                                             \\\\\n        &\\hspace{5mm}if \\: centered                                                          \\\\\n        &\\hspace{10mm} g^{ave}_t \\leftarrow g^{ave}_{t-1} \\alpha + (1-\\alpha) g_t            \\\\\n        &\\hspace{10mm} \\tilde{v_t} \\leftarrow \\tilde{v_t} -  \\big(g^{ave}_{t} \\big)^2        \\\\\n        &\\hspace{5mm}if \\: \\mu > 0                                                           \\\\\n        &\\hspace{10mm} \\textbf{b}_t\\leftarrow \\mu \\textbf{b}_{t-1} +\n            g_t/ \\big(\\sqrt{\\tilde{v_t}} +  \\epsilon \\big)                                   \\\\\n        &\\hspace{10mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\textbf{b}_t                \\\\\n        &\\hspace{5mm} else                                                                   \\\\\n        &\\hspace{10mm}\\theta_t      \\leftarrow   \\theta_{t-1} -\n            \\gamma  g_t/ \\big(\\sqrt{\\tilde{v_t}} + \\epsilon \\big)  \\hspace{3mm}              \\\\\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n        &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n        &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n   \\end{aligned}\n\nFor further details regarding the algorithm we refer to\n`lecture notes <https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_ by G. Hinton.\nand centered version `Generating Sequences\nWith Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>`_.\nThe implementation here takes the square root of the gradient average before\nadding epsilon (note that TensorFlow interchanges these two operations). The effective\nlearning rate is thus :math:`\\gamma/(\\sqrt{v} + \\epsilon)` where :math:`\\gamma`\nis the scheduled learning rate and :math:`v` is the weighted moving average\nof the squared gradient.\n\nArgs:\n    params (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n    lr (float, optional): learning rate (default: 1e-2)\n    momentum (float, optional): momentum factor (default: 0)\n    alpha (float, optional): smoothing constant (default: 0.99)\n    eps (float, optional): term added to the denominator to improve\n        numerical stability (default: 1e-8)\n    centered (bool, optional) : if ``True``, compute the centered RMSProp,\n        the gradient is normalized by an estimation of its variance\n    weight_decay (float, optional): weight decay (L2 penalty) (default: 0)",
    "docstring_sections": [
        {
            "type": "parameters",
            "value": [
                {
                    "annotation": "iterable",
                    "default": "",
                    "description": "iterable of parameters to optimize or dicts defining\nparameter groups",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": false,
                    "is_required": true,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "params"
                },
                {
                    "annotation": "float",
                    "default": "0.01",
                    "description": "learning rate (default: 1e-2)",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": true,
                    "is_required": false,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "lr"
                },
                {
                    "annotation": "float",
                    "default": "0",
                    "description": "momentum factor (default: 0)",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": true,
                    "is_required": false,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "momentum"
                },
                {
                    "annotation": "float",
                    "default": "0.99",
                    "description": "smoothing constant (default: 0.99)",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": true,
                    "is_required": false,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "alpha"
                },
                {
                    "annotation": "float",
                    "default": "1e-08",
                    "description": "term added to the denominator to improve\nnumerical stability (default: 1e-8)",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": true,
                    "is_required": false,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "eps"
                },
                {
                    "annotation": "bool, optional) ",
                    "default": "False",
                    "description": "if ``True``, compute the centered RMSProp,\nthe gradient is normalized by an estimation of its variance",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": true,
                    "is_required": false,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "centered"
                },
                {
                    "annotation": "float",
                    "default": "0",
                    "description": "weight decay (L2 penalty) (default: 0)",
                    "is_args": false,
                    "is_kwargs": false,
                    "is_optional": true,
                    "is_required": false,
                    "kind": "POSITIONAL_OR_KEYWORD",
                    "name": "weight_decay"
                }
            ]
        }
    ],
    "name": "RMSprop",
    "path": "torch.optim.rmsprop.RMSprop"
}
