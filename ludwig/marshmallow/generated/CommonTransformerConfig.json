{
    "attributes": [
        "ludwig.combiners.combiners.CommonTransformerConfig.num_layers",
        "ludwig.combiners.combiners.CommonTransformerConfig.hidden_size",
        "ludwig.combiners.combiners.CommonTransformerConfig.num_heads",
        "ludwig.combiners.combiners.CommonTransformerConfig.transformer_output_size",
        "ludwig.combiners.combiners.CommonTransformerConfig.dropout",
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_layers",
        "ludwig.combiners.combiners.CommonTransformerConfig.num_fc_layers",
        "ludwig.combiners.combiners.CommonTransformerConfig.output_size",
        "ludwig.combiners.combiners.CommonTransformerConfig.use_bias",
        "ludwig.combiners.combiners.CommonTransformerConfig.weights_initializer",
        "ludwig.combiners.combiners.CommonTransformerConfig.bias_initializer",
        "ludwig.combiners.combiners.CommonTransformerConfig.norm",
        "ludwig.combiners.combiners.CommonTransformerConfig.norm_params",
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_activation",
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_dropout",
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_residual"
    ],
    "bases": [
        "object"
    ],
    "children": {
        "ludwig.combiners.combiners.CommonTransformerConfig.__init__": {
            "docstring": null,
            "name": "__init__",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.__init__",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "signature": {
                "parameters": [
                    {
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "self"
                    },
                    {
                        "annotation": "int",
                        "default": "1",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "num_layers"
                    },
                    {
                        "annotation": "int",
                        "default": "256",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "hidden_size"
                    },
                    {
                        "annotation": "int",
                        "default": "8",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "num_heads"
                    },
                    {
                        "annotation": "int",
                        "default": "256",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "transformer_output_size"
                    },
                    {
                        "annotation": "float",
                        "default": "0.1",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "dropout"
                    },
                    {
                        "annotation": "Optional[List[Dict[str, Any]]]",
                        "default": "<factory>",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "fc_layers"
                    },
                    {
                        "annotation": "int",
                        "default": "0",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "num_fc_layers"
                    },
                    {
                        "annotation": "int",
                        "default": "256",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "output_size"
                    },
                    {
                        "annotation": "bool",
                        "default": "True",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "use_bias"
                    },
                    {
                        "annotation": "Union[str, Dict]",
                        "default": "'xavier_uniform'",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "weights_initializer"
                    },
                    {
                        "annotation": "Union[str, Dict]",
                        "default": "'zeros'",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "bias_initializer"
                    },
                    {
                        "annotation": "Optional[str]",
                        "default": "None",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "norm"
                    },
                    {
                        "annotation": "Optional[dict]",
                        "default": "<factory>",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "norm_params"
                    },
                    {
                        "annotation": "str",
                        "default": "'relu'",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "fc_activation"
                    },
                    {
                        "annotation": "float",
                        "default": "0.0",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "fc_dropout"
                    },
                    {
                        "annotation": "bool",
                        "default": "False",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "fc_residual"
                    }
                ],
                "return_annotation": "None"
            }
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.bias_initializer": {
            "docstring": "TODO: Document parameters. (default: 'zeros').",
            "name": "bias_initializer",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.bias_initializer",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "Union[str, Dict]"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.dropout": {
            "docstring": "Dropout rate for the transformer block (default: 0.1).",
            "name": "dropout",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.dropout",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_activation": {
            "docstring": "TODO: Document parameters. (default: 'relu').",
            "name": "fc_activation",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.fc_activation",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "str"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_dropout": {
            "docstring": "TODO: Document parameters. (default: 0.0).",
            "name": "fc_dropout",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.fc_dropout",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_layers": {
            "docstring": "TODO: Document parameters. (default: None).",
            "name": "fc_layers",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.fc_layers",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "Optional[List[Dict[str, Any]]]"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.fc_residual": {
            "docstring": "TODO: Document parameters. (default: False).",
            "name": "fc_residual",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.fc_residual",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "bool"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.hidden_size": {
            "docstring": "The number of hidden units of the TransformerStack as well as the dimension that each incoming input feature is\nprojected to before feeding to the TransformerStack (default: 256).",
            "name": "hidden_size",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.hidden_size",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.norm": {
            "docstring": "TODO: Document parameters. (default: None).",
            "name": "norm",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.norm",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "Optional[str]"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.norm_params": {
            "docstring": "TODO: Document parameters. (default: None).",
            "name": "norm_params",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.norm_params",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "Optional[dict]"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.num_fc_layers": {
            "docstring": "The number of stacked fully connected layers (only applies if `reduce_output` is not null) (default: 0).",
            "name": "num_fc_layers",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.num_fc_layers",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.num_heads": {
            "docstring": "Number of heads of the self attention in the transformer block (default: 8).",
            "name": "num_heads",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.num_heads",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.num_layers": {
            "docstring": "TODO: Document parameters. (default: 1).",
            "name": "num_layers",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.num_layers",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.output_size": {
            "docstring": "Output size of a fully connected layer (default: 256).",
            "name": "output_size",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.output_size",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.transformer_output_size": {
            "docstring": "Size of the fully connected layer after self attention in the transformer block. This is usually the same as\n`hidden_size` and `embedding_size` (default: 256).",
            "name": "transformer_output_size",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.transformer_output_size",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.use_bias": {
            "docstring": "Whether the layer uses a bias vector (default: True).",
            "name": "use_bias",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.use_bias",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "bool"
        },
        "ludwig.combiners.combiners.CommonTransformerConfig.weights_initializer": {
            "docstring": "TODO: Document parameters. (default: 'xavier_uniform').",
            "name": "weights_initializer",
            "path": "ludwig.combiners.combiners.CommonTransformerConfig.weights_initializer",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "Union[str, Dict]"
        }
    },
    "docstring": "Common transformer parameter values.",
    "name": "CommonTransformerConfig",
    "path": "ludwig.combiners.combiners.CommonTransformerConfig"
}
