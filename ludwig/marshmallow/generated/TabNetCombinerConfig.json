{
    "attributes": [
        "ludwig.combiners.combiners.TabNetCombinerConfig.size",
        "ludwig.combiners.combiners.TabNetCombinerConfig.output_size",
        "ludwig.combiners.combiners.TabNetCombinerConfig.num_steps",
        "ludwig.combiners.combiners.TabNetCombinerConfig.num_total_blocks",
        "ludwig.combiners.combiners.TabNetCombinerConfig.num_shared_blocks",
        "ludwig.combiners.combiners.TabNetCombinerConfig.relaxation_factor",
        "ludwig.combiners.combiners.TabNetCombinerConfig.bn_epsilon",
        "ludwig.combiners.combiners.TabNetCombinerConfig.bn_momentum",
        "ludwig.combiners.combiners.TabNetCombinerConfig.bn_virtual_bs",
        "ludwig.combiners.combiners.TabNetCombinerConfig.sparsity",
        "ludwig.combiners.combiners.TabNetCombinerConfig.entmax_mode",
        "ludwig.combiners.combiners.TabNetCombinerConfig.entmax_alpha",
        "ludwig.combiners.combiners.TabNetCombinerConfig.dropout"
    ],
    "bases": [
        "ludwig.combiners.combiners.BaseCombinerConfig"
    ],
    "children": {
        "ludwig.combiners.combiners.TabNetCombinerConfig.__init__": {
            "docstring": null,
            "name": "__init__",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.__init__",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "signature": {
                "parameters": [
                    {
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "self"
                    },
                    {
                        "annotation": "int",
                        "default": "32",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "size"
                    },
                    {
                        "annotation": "int",
                        "default": "32",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "output_size"
                    },
                    {
                        "annotation": "int",
                        "default": "1",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "num_steps"
                    },
                    {
                        "annotation": "int",
                        "default": "4",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "num_total_blocks"
                    },
                    {
                        "annotation": "int",
                        "default": "2",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "num_shared_blocks"
                    },
                    {
                        "annotation": "float",
                        "default": "1.5",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "relaxation_factor"
                    },
                    {
                        "annotation": "float",
                        "default": "0.001",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "bn_epsilon"
                    },
                    {
                        "annotation": "float",
                        "default": "0.7",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "bn_momentum"
                    },
                    {
                        "annotation": "Optional[int]",
                        "default": "None",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "bn_virtual_bs"
                    },
                    {
                        "annotation": "float",
                        "default": "1e-05",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "sparsity"
                    },
                    {
                        "annotation": "str",
                        "default": "'sparsemax'",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "entmax_mode"
                    },
                    {
                        "annotation": "float",
                        "default": "1.5",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "entmax_alpha"
                    },
                    {
                        "annotation": "float",
                        "default": "0.0",
                        "kind": "POSITIONAL_OR_KEYWORD",
                        "name": "dropout"
                    }
                ],
                "return_annotation": "None"
            }
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.bn_epsilon": {
            "docstring": "Epsilon to be added to the batch norm denominator (default: 1e-3).",
            "name": "bn_epsilon",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.bn_epsilon",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.bn_momentum": {
            "docstring": "Momentum of the batch norm. `m_B` in the paper (default: 0.7).",
            "name": "bn_momentum",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.bn_momentum",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.bn_virtual_bs": {
            "docstring": "Size of the virtual batch size used by ghost batch norm. If null, regular batch norm is used instead. `B_v` from\nthe paper (default: None).",
            "name": "bn_virtual_bs",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.bn_virtual_bs",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "Optional[int]"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.dropout": {
            "docstring": "Dropout rate for the transformer block (default: 0.0).",
            "name": "dropout",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.dropout",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.entmax_alpha": {
            "docstring": "TODO: Document parameters. (default: 1.5)",
            "name": "entmax_alpha",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.entmax_alpha",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.entmax_mode": {
            "docstring": "TODO: Document parameters. (default: 'sparsemax')",
            "name": "entmax_mode",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.entmax_mode",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "str"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.num_shared_blocks": {
            "docstring": "Number of shared feature transformer blocks across the steps (default: 2).",
            "name": "num_shared_blocks",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.num_shared_blocks",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.num_steps": {
            "docstring": "Number of steps / repetitions of the the attentive transformer and feature transformer computations. `N_steps` in\nthe paper (default: 1).",
            "name": "num_steps",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.num_steps",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.num_total_blocks": {
            "docstring": "Total number of feature transformer block at each step (default: 4).",
            "name": "num_total_blocks",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.num_total_blocks",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.output_size": {
            "docstring": "Output size of a fully connected layer. `N_d` in the paper (default: 32).",
            "name": "output_size",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.output_size",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.relaxation_factor": {
            "docstring": "Factor that influences how many times a feature should be used across the steps of computation. a value of 1\nimplies it each feature should be use once, a higher value allows for multiple usages. `gamma` in the paper\n(default: 1.5).",
            "name": "relaxation_factor",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.relaxation_factor",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.size": {
            "docstring": "`N_a` in the paper (default: 32).",
            "name": "size",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.size",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "int"
        },
        "ludwig.combiners.combiners.TabNetCombinerConfig.sparsity": {
            "docstring": "Multiplier of the sparsity inducing loss. `lambda_sparse` in the paper (default: 1e-5).",
            "name": "sparsity",
            "path": "ludwig.combiners.combiners.TabNetCombinerConfig.sparsity",
            "relative_file_path": "ludwig/combiners/combiners.py",
            "type": "float"
        }
    },
    "docstring": "Parameters for tabnet combiner.",
    "name": "TabNetCombinerConfig",
    "path": "ludwig.combiners.combiners.TabNetCombinerConfig"
}
