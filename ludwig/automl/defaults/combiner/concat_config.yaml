combiner:
  type: concat

hyperopt:
  # goal: maximize
  parameters:
    combiner.num_fc_layers:
      space: randint
      lower: 1
      upper: 4
    combiner.output_size:
      space: choice
      categories: [128, 256]
    combiner.dropout:
      space: uniform
      lower: 0.0
      upper: 0.1
    # This needs to be loguniform due to invalid schemas created by merging with a choice parameter space. See the
    # comment in ludwig/automl/defaults/text/bert_config.yaml for more information.
    trainer.learning_rate:
      space: loguniform
      lower: 0.00002
      upper: 0.001
    trainer.batch_size:
      space: choice
      categories: [64, 128, 256, 512, 1024]
