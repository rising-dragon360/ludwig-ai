input_features:
  - name: lepton_pT
    type: number
  - name: lepton_eta
    type: number
  - name: lepton_phi
    type: number
  - name: missing_energy_magnitude
    type: number
  - name: missing_energy_phi
    type: number
  - name: jet_1_pt
    type: number
  - name: jet_1_eta
    type: number
  - name: jet_1_phi
    type: number
  - name: jet_1_b-tag
    type: number
  - name: jet_2_pt
    type: number
  - name: jet_2_eta
    type: number
  - name: jet_2_phi
    type: number
  - name: jet_2_b-tag
    type: number
  - name: jet_3_pt
    type: number
  - name: jet_3_eta
    type: number
  - name: jet_3_phi
    type: number
  - name: jet_3_b-tag
    type: number
  - name: jet_4_pt
    type: number
  - name: jet_4_eta
    type: number
  - name: jet_4_phi
    type: number
  - name: jet_4_b-tag
    type: number
  - name: m_jj
    type: number
  - name: m_jjj
    type: number
  - name: m_lv
    type: number
  - name: m_jlv
    type: number
  - name: m_bb
    type: number
  - name: m_wbb
    type: number
  - name: m_wwbb
    type: number
output_features:
  - name: label
    type: binary
    weight_regularization: null
combiner:
  type: tabnet
  size: 24 # N_a
  output_size: 26 # N_d
  sparsity: 0.000001 # lambda_sparse
  bn_virtual_divider: 32 # factor to divide batch_size B to get B_v from the paper
  bn_momentum: 0.4 # m_B
  num_steps: 5 # N_steps
  relaxation_factor: 1.5 # gamma
  bn_virtual_bs: 512 # B_v
trainer:
  batch_size: 16384 # B
  eval_batch_size: 500000 # 65536 131072 262144 524288
  epochs: 1000
  early_stop: 20
  learning_rate: 0.02
  optimizer:
    type: adam
  learning_rate_scheduler:
    decay: exponential
    decay_steps: 20000
    decay_rate: 0.9
    staircase: true
  validation_field: label
