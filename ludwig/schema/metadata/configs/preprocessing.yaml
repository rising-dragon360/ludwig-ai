force_split:
    default_value_reasoning:
        We do not expect most datasets to have an explicit "split"
        column in the data. Used mostly internally by ludwig datasets.
    expected_impact: 3
    related_parameters:
        - split_probabilities, stratify
    ui_display_name: Force Split
oversample_minority:
    default_value_reasoning:
        We do not want to randomly oversample by default since
        this is a strategy to deal with imbalanced datasets, but can cause issues
        if not implemented correctly.
    description_implications:
        The higher the value you choose gets to 1, the closer
        you will be to having an equal imbalance ratio (i.e. 1:1 positive to negative
        class), however this can lead to problems of overfitting when oversampling
        is used too liberally. As a rule of thumb, starting oversampling with a very
        conservative approach and increasing in small incremements is probably the
        best way to improve your model without experiencing model overfitting.
    example_value:
        - 0.5
    expected_impact: 2
    literature_references:
        - https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/
    other_information:
        This parameter is one of many strategies to combat issues with
        class imbalance, though it is not a cure all. Oversampling too much can cause
        overfitting which can adversely affect your model so use with caution.
    suggested_values: Depends on imbalance ratio and dataset size
    ui_display_name: Oversample Minority
sample_ratio:
    default_value_reasoning:
        The default value is 1.0 because we do not want to shrink
        the dataset by default. In the rare occurences when you do want to downsample
        the entire dataset, this parameter is available, however it is not enabled
        by default, hence a default value of 1.0
    description_implications:
        Decreases the amount of data you are inputting into
        the model. Could be useful if you have more data than you need and you are
        concerned with computational costs.
    example_value:
        - 0.8
    expected_impact: 2
    suggested_values: Depends on data size
    ui_display_name: Sample Ratio
sample_size:
    default_value_reasoning:
        The default value is None because we do not want to shrink
        the dataset by default, and we do not know the size of an arbitrary dataset.
        By setting the default to None, we fall back on the sample_ratio to determine
        the size of the dataset.
    description_implications:
        Decreases the amount of data you are inputting into
        the model. Could be useful if you have more data than you need and you are
        concerned with computational costs. More useful than sample_ratio if you
        know the exact number of samples you want to train on instead of knowing the proportion.
    example_value:
        - 1000
    expected_impact: 2
    suggested_values: Depends on data size
    ui_display_name: Sample Size
column:
    expected_impact: 3
    ui_display_name: Split Column
    ui_component_type: column_selector
split_probabilities:
    default_value_reasoning:
        Most of the dataset should be used for training, with
        some portion heldout for validation and testing.
    description_implications:
        "In machine learning, data splitting is typically done
        to avoid overfitting. That is an instance where a machine learning model fits
        its training data too well and fails to reliably fit additional data.


        The training set is the portion of data used to train the model. The model
        should observe and learn from the training set, optimizing any of its parameters.


        The dev set is a data set of examples used to change learning process parameters.
        It is also called the cross-validation or model validation set. This set of
        data has the goal of ranking the model's accuracy and can help with model
        selection.


        The testing set is the portion of data that is tested in the final model and
        is compared against the previous sets of data. The testing set acts as an
        evaluation of the final mode and algorithm."
    expected_impact: 3
    literature_references:
        - "https://www.techtarget.com/searchenterpriseai/definition/data-splitting#:~:text=Data%20splitting%20is%20when%20data,creating%20models%20based%20on%20data. "
    other_information: "Split data into train, validation, and test.


        By default, Ludwig looks for a column named split (case-sensitive) which is
        expected to consist of 3 possible values that correspond to different datasets:


        0: train

        1: validation

        2: test

        If the data does not contain the split column, then data is randomly split
        based on splitting percentages, defined by split_probabilities.


        If force_split is true, the the split column in the dataset is ignored and
        the dataset is randomly split based on splitting percentages, defined by split_probabilities."
    related_parameters:
        - force_split, stratify
    suggested_values:
        - 0.8
        - 0.1
        - 0.1
    suggested_values_reasoning:
        For larger datasets, it can be beneficial to use more
        data for training, since the test and validation sets are still plenty big
        for getting a good sense of model generalization.
    ui_display_name: Split Probabilities
stratify:
    default_value_reasoning:
        The default is set to None since we do not want to stratify
        unless specifically told to do so. There are a variety of reasons for this,
        but one example is that our data set may not even have a categorical feature
        to stratify on.
    description_implications: Depends on dataset
    example_value:
        - Category_Feature_A
    expected_impact: 3
    literature_references:
        - https://medium.com/analytics-vidhya/stratified-sampling-in-machine-learning-f5112b5b9cfe
    related_parameters:
        - force_split, split_probabilities
    suggested_values: Depends on dataset
    ui_display_name: Stratify
undersample_majority:
    default_value_reasoning:
        We do not want to randomly undersample by default since
        this is a strategy to deal with imbalanced datasets, but can cause issues
        if not implemented correctly.
    description_implications:
        The higher the value you choose gets to 1, the closer
        you will be to having an equal imbalance ratio (i.e. 1:1 positive to negative
        class), however this can lead to problems of data loss when undersampling
        is used too liberally. As a rule of thumb, starting undersampling with a very
        conservative approach and increasing in small incremements is probably the
        best way to improve your model without experiencing catastrophic data loss
        effects.
    example_value:
        - 0.5
    expected_impact: 2
    literature_references:
        - https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/
    other_information:
        This parameter is one of many strategies to combat issues with
        class imbalance, though it is not a cure all. Undersampling too much can cause
        loss of data which can adversely affect your model so use with caution.
    suggested_values: Depends on imbalance ratio and dataset size
    ui_display_name: Undersample Majority
cache_encoder_embeddings:
    default_value_reasoning:
        Caching encoder embeddings means preprocessed data is not reusable across other model architectures, so
        it's not always the case that you would always want to enable it when possible.
    expected_impact: 1
    ui_display_name: Cache Encoder Embeddings
global_max_sequence_length:
    expected_impact: 2
    ui_display_name: Global Max Sequence Length
    description_implications:
        Specifically for LLMs. This is the maximum number of tokens going into the model's forward pass during training. Sequences will be truncated to this length after merging the tokens from the input with tokens from the target. If not set, the total length of the merged input and target token sequences will be used.
    example_value:
        - 512
